{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8685641a",
   "metadata": {},
   "source": [
    "# Orchestrazione completa del flusso di Ticket Triage Automatico\n",
    "\n",
    "Questo notebook ha lo scopo di orchestrare end-to-end l’intero prototipo di **classificazione automatica dei ticket di assistenza**, sviluppato nell’ambito del Project Work.\n",
    "\n",
    "In un unico flusso riproducibile vengono eseguite tutte le fasi principali:\n",
    "- analisi di un dataset sintetico di ticket e suo split in sotto dataset di training e test,\n",
    "- addestramento dei modelli di Machine Learning prescelti e valutazione delle prestazioni,\n",
    "- comparazione dei modelli e salvataggio degli artefatti.\n",
    "\n",
    "Il notebook non introduce nuova logica applicativa, ma coordina moduli già definiti ed eseguibili singolarmente, fungendo da punto di ingresso unico per l’esecuzione completa del progetto.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851626d8",
   "metadata": {},
   "source": [
    "## Inizializzazione dell’ambiente di lavoro\n",
    "\n",
    "In questa sezione vengono importate le librerie necessarie e definite le variabili di contesto condivise (percorsi di progetto, directory dati e output).\n",
    "\n",
    "L’obiettivo è garantire:\n",
    "- indipendenza dal sistema operativo,\n",
    "- coerenza dei path tra notebook e script,\n",
    "- possibilità di esecuzione del flusso da un unico punto.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "6152882f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\project-work\\.venv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import papermill as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c1487961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: C:\\project-work\n",
      "RUN_ID: 20260105_230145\n",
      "OUTPUT_DIR: C:\\project-work\\runs\\20260105_230145\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ROOT = Path(\"..\").resolve()  # perché sei dentro /notebooks\n",
    "NOTEBOOKS_DIR = PROJECT_ROOT / \"notebooks\"\n",
    "RUN_ID = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "OUTPUT_DIR = PROJECT_ROOT / \"runs\" / RUN_ID\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"RUN_ID:\", RUN_ID)\n",
    "print(\"OUTPUT_DIR:\", OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110a79f0",
   "metadata": {},
   "source": [
    "# Predisposizione della pipeline \n",
    "\n",
    "Tutti i notebooks vengono inseriti in pipeline e vengono predisposte le condizione di esecuzione.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "bd17abe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook in pipeline: 6\n"
     ]
    }
   ],
   "source": [
    "pipeline = [\n",
    "    \"01_exploration_dataset.ipynb\",\n",
    "    \"02_preprocessing_dataset.ipynb\",\n",
    "    \"03_TFIDF_Logic_Regression.ipynb\",\n",
    "    \"04_TFIDF_LinearSVM.ipynb\",\n",
    "    \"05_Naive_Bayes_Exploration.ipynb\",\n",
    "    \"06_Model_Result_Compare.ipynb\",\n",
    "]\n",
    "\n",
    "for nb in pipeline:\n",
    "    nb_path = NOTEBOOKS_DIR / nb\n",
    "    if not nb_path.exists():\n",
    "        raise FileNotFoundError(f\"Notebook non trovato: {nb_path}\")\n",
    "\n",
    "print(\"Notebook in pipeline:\", len(pipeline))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f97216df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_notebook(input_name: str) -> Path:\n",
    "    input_path = NOTEBOOKS_DIR / input_name\n",
    "    output_path = OUTPUT_DIR / input_name.replace(\".ipynb\", \"_out.ipynb\")\n",
    "\n",
    "    print(f\"\\n=== ESEGUO: {input_name} ===\")\n",
    "    pm.execute_notebook(\n",
    "        input_path=str(input_path),\n",
    "        output_path=str(output_path),\n",
    "        cwd=str(PROJECT_ROOT),  \n",
    "    )\n",
    "    print(f\"OK: salvato -> {output_path}\")\n",
    "    return output_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb5f220",
   "metadata": {},
   "source": [
    "## Esecuzione sequenziale della pipeline di notebook\n",
    "\n",
    "In questa sezione viene eseguita l’intera pipeline del progetto attraverso il lancio sequenziale dei notebook che compongono il flusso di lavoro.\n",
    "\n",
    "Ogni notebook rappresenta una fase autonoma e logicamente coerente del processo (ad esempio split dei dati, addestramento dei modelli, valutazione).  \n",
    "L’esecuzione avviene in modo controllato e ordinato, garantendo che ogni step venga completato prima di passare al successivo.\n",
    "\n",
    "I notebook eseguiti correttamente vengono tracciati e riportati a fine esecuzione, fornendo un riscontro immediato sul completamento dell’intera pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "09eb13b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ESEGUO: 01_exploration_dataset.ipynb ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing: 100%|██████████| 29/29 [00:09<00:00,  2.98cell/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: salvato -> C:\\project-work\\runs\\20260105_230145\\01_exploration_dataset_out.ipynb\n",
      "\n",
      "=== ESEGUO: 02_preprocessing_dataset.ipynb ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing: 100%|██████████| 16/16 [00:05<00:00,  2.73cell/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: salvato -> C:\\project-work\\runs\\20260105_230145\\02_preprocessing_dataset_out.ipynb\n",
      "\n",
      "=== ESEGUO: 03_TFIDF_Logic_Regression.ipynb ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing: 100%|██████████| 28/28 [00:14<00:00,  1.90cell/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: salvato -> C:\\project-work\\runs\\20260105_230145\\03_TFIDF_Logic_Regression_out.ipynb\n",
      "\n",
      "=== ESEGUO: 04_TFIDF_LinearSVM.ipynb ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing: 100%|██████████| 28/28 [00:10<00:00,  2.71cell/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: salvato -> C:\\project-work\\runs\\20260105_230145\\04_TFIDF_LinearSVM_out.ipynb\n",
      "\n",
      "=== ESEGUO: 05_Naive_Bayes_Exploration.ipynb ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing: 100%|██████████| 28/28 [00:07<00:00,  3.58cell/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: salvato -> C:\\project-work\\runs\\20260105_230145\\05_Naive_Bayes_Exploration_out.ipynb\n",
      "\n",
      "=== ESEGUO: 06_Model_Result_Compare.ipynb ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing: 100%|██████████| 3/3 [00:07<00:00,  2.42s/cell]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: salvato -> C:\\project-work\\runs\\20260105_230145\\06_Model_Result_Compare_out.ipynb\n",
      "\n",
      "Pipeline completata. Notebook eseguiti:\n",
      "- C:\\project-work\\runs\\20260105_230145\\01_exploration_dataset_out.ipynb\n",
      "- C:\\project-work\\runs\\20260105_230145\\02_preprocessing_dataset_out.ipynb\n",
      "- C:\\project-work\\runs\\20260105_230145\\03_TFIDF_Logic_Regression_out.ipynb\n",
      "- C:\\project-work\\runs\\20260105_230145\\04_TFIDF_LinearSVM_out.ipynb\n",
      "- C:\\project-work\\runs\\20260105_230145\\05_Naive_Bayes_Exploration_out.ipynb\n",
      "- C:\\project-work\\runs\\20260105_230145\\06_Model_Result_Compare_out.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "executed = []\n",
    "\n",
    "for nb in pipeline:\n",
    "    out = run_notebook(nb)\n",
    "    executed.append(out)\n",
    "\n",
    "print(\"\\nPipeline completata. Notebook eseguiti:\")\n",
    "for p in executed:\n",
    "    print(\"-\", p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975675c9",
   "metadata": {},
   "source": [
    "## Tracciamento dell’esecuzione della pipeline\n",
    "\n",
    "Al termine dell’esecuzione della pipeline, viene generato un file di log che documenta in modo persistente l’esito del run corrente.\n",
    "\n",
    "Il log contiene:\n",
    "- un identificativo univoco di esecuzione (RUN_ID),\n",
    "- l’elenco dei notebook eseguiti correttamente.\n",
    "\n",
    "All'interno della cartella di archivio run, identificata tramite la codice di data e ore di esecuzione (aaaammgg_hhmmss):\n",
    "- file di log di esecuzione,\n",
    "- file di dataset grezzo utilizzato,\n",
    "- output dei singoli notebooks.\n",
    "\n",
    "I dati storicizzati permetteranno una analisi a posteriori, confronti ed eventuali rielaborazioni.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "0b2192f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log salvato in: C:\\project-work\\runs\\20260105_230145\\run_log.txt\n"
     ]
    }
   ],
   "source": [
    "log_path = OUTPUT_DIR / \"run_log.txt\"\n",
    "\n",
    "with open(log_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(f\"RUN_ID: {RUN_ID}\\n\")\n",
    "    f.write(\"Executed notebooks:\\n\")\n",
    "    for p in executed:\n",
    "        f.write(f\"- {p.name}\\n\")\n",
    "\n",
    "print(\"Log salvato in:\", log_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
